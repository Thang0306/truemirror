import os
from openai import OpenAI

class AzureGPTService:
    def __init__(self):
        # Azure OpenAI Configuration - using standard OpenAI client with base_url
        api_key = os.getenv('AZURE_OPENAI_KEY')
        base_url = os.getenv('AZURE_OPENAI_BASE_URL')

        if not api_key or not base_url:
            raise ValueError("AZURE_OPENAI_KEY and AZURE_OPENAI_BASE_URL must be set")

        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        self.model = os.getenv('AZURE_OPENAI_DEPLOYMENT', 'gpt-4.1')
        print(f"[INFO] Azure OpenAI initialized: model={self.model}, base_url={base_url}")

    def get_chat_response_stream(self, conversation_history):
        """
        Get streaming chat response from Azure OpenAI
        conversation_history: list of {role, content} dicts
        Yields: content chunks from AI response
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=conversation_history,
                temperature=0.7,
                max_tokens=1000,
                stream=True
            )

            for chunk in response:
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        # Debug: print chunk content
                        print(f"[DEBUG] Chunk: {repr(delta.content)}")
                        yield delta.content

        except Exception as e:
            print(f"[ERROR] Azure OpenAI stream failed: {str(e)}")
            yield f"Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra: {str(e)}"

    def build_interview_system_prompt(self, position, industry, style, language, uploaded_files_info=None):
        """Build system prompt based on interview configuration"""

        style_instructions = {
            'Nghi√™m t√∫c': 'B·∫°n l√† m·ªôt interviewer nghi√™m t√∫c v√† chuy√™n nghi·ªáp. B·∫°n ƒë·∫∑t c√¢u h·ªèi s√¢u s·∫Øc v√† ƒë√°nh gi√° k·ªπ nƒÉng m·ªôt c√°ch ch√≠nh x√°c.',
            'Th√¢n thi·ªán': 'B·∫°n l√† m·ªôt interviewer th√¢n thi·ªán v√† khuy·∫øn kh√≠ch. B·∫°n t·∫°o kh√¥ng kh√≠ tho·∫£i m√°i nh∆∞ng v·∫´n ƒë√°nh gi√° ƒë·∫ßy ƒë·ªß k·ªπ nƒÉng.',
            'Kh√≥ t√≠nh': 'B·∫°n l√† m·ªôt interviewer kh√≥ t√≠nh v√† y√™u c·∫ßu cao. B·∫°n ƒë·∫∑t c√¢u h·ªèi th√°ch th·ª©c v√† ph·∫£n bi·ªán c√°c c√¢u tr·∫£ l·ªùi.'
        }

        lang_instruction = ''
        if language == 'vi':
            lang_instruction = 'B·∫°n PH·∫¢I tr·∫£ l·ªùi HO√ÄN TO√ÄN b·∫±ng ti·∫øng Vi·ªát.'
        else:
            lang_instruction = 'You MUST respond ENTIRELY in English.'

        # Add personalized candidate context if available
        candidate_context = ""
        if uploaded_files_info:
            import json
            info = json.loads(uploaded_files_info) if isinstance(uploaded_files_info, str) else uploaded_files_info
            candidate_context = f"""
CANDIDATE CONTEXT (from uploaded documents):
- Skills: {', '.join(info.get('candidate_skills', []))}
- Experience Level: {info.get('experience_level', 'Unknown')}
- Background: {info.get('candidate_background', 'N/A')}
- Key Focus Areas: {', '.join(info.get('key_focus_areas', []))}

Use this context to tailor your questions and feedback to the candidate's specific background.
"""

        system_prompt = f"""
{style_instructions.get(style, style_instructions['Nghi√™m t√∫c'])}

B·∫°n t√™n l√† TrueMirror, l√† m·ªôt AI Interviewer, gi·ªõi t√≠nh n·ªØ. B·∫°n
ƒëang ph·ªèng v·∫•n ·ª©ng vi√™n cho v·ªã tr√≠ {position} trong ng√†nh {industry}.

{candidate_context}

{lang_instruction}

FLOW PH·ªéNG V·∫§N LINH HO·∫†T:
B·∫°n ƒë∆∞·ª£c cung c·∫•p m·ªôt b·ªô c√¢u h·ªèi c√≥ c·∫•u tr√∫c b√™n d∆∞·ªõi. H√£y tu√¢n th·ªß flow sau:

1. B·∫ÆT ƒê·∫¶U: Ch√†o h·ªèi ng·∫Øn g·ªçn, gi·ªõi thi·ªáu b·∫£n th√¢n l√† "TrueMirror" (KH√îNG d√πng [T√™n] hay t√™n gi·∫£ ƒë·ªãnh kh√°c) v√† h·ªèi c√¢u h·ªèi ƒë·∫ßu ti√™n t·ª´ Section 1.

2. TRONG QU√Å TR√åNH:
   - L·∫Øng nghe c√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n
   - ƒê∆∞a ra feedback ng·∫Øn g·ªçn v√† real-time (1-2 c√¢u) v·ªÅ c√¢u tr·∫£ l·ªùi:
     * N·∫øu t·ªët: Khen ng·ª£i ƒëi·ªÉm m·∫°nh c·ª• th·ªÉ
     * N·∫øu thi·∫øu: G·ª£i √Ω nh·∫π nh√†ng ƒëi·ªÉm c·∫ßn b·ªï sung
   - ƒê√°nh gi√° n·ªôi b·ªô (kh√¥ng n√≥i ra) d·ª±a tr√™n guidelines (must_have/should_avoid)
   - N·∫øu c√¢u tr·∫£ l·ªùi ch∆∞a ƒë·ªß chi ti·∫øt: H·ªèi POP-UP question ƒë·ªÉ ƒë√†o s√¢u
   - N·∫øu c√¢u tr·∫£ l·ªùi ƒë√£ ƒë·ªß: Chuy·ªÉn sang c√¢u h·ªèi ti·∫øp theo

3. T√çNH LINH HO·∫†T:
   - N·∫øu ·ª©ng vi√™n h·ªèi l·∫°i ho·∫∑c c·∫ßn l√†m r√µ: Tr·∫£ l·ªùi t·ª± nhi√™n, h·ªØu √≠ch
   - N·∫øu ·ª©ng vi√™n ƒëi ch·ªách topic: Nh·∫π nh√†ng d·∫´n v·ªÅ c√¢u h·ªèi ch√≠nh
   - N·∫øu ·ª©ng vi√™n stress: ƒêi·ªÅu ch·ªânh tone th√¢n thi·ªán h∆°n
   - Ch·∫•p nh·∫≠n c√¢u tr·∫£ l·ªùi ng·∫Øn n·∫øu ·ª©ng vi√™n kh√¥ng c√≥ kinh nghi·ªám (Intern/Junior)

4. TH·ª® T·ª∞ C√ÇU H·ªéI:
   - ƒêi theo th·ª© t·ª± Section ‚Üí Question trong b·ªô c√¢u h·ªèi
   - ƒê·∫£m b·∫£o h·ªèi ƒë·ªß c√¢u h·ªèi quan tr·ªçng nh·∫•t t·ª´ m·ªói section
   - C√≥ th·ªÉ skip c√¢u h·ªèi n·∫øu ·ª©ng vi√™n ƒë√£ tr·∫£ l·ªùi t·ª± nhi√™n trong c√¢u tr∆∞·ªõc

5. K·∫æT TH√öC:
   - Sau khi h·ªèi xong c√°c c√¢u h·ªèi ch√≠nh: H·ªèi xem ·ª©ng vi√™n c√≥ c√¢u h·ªèi n√†o kh√¥ng
   - C·∫£m ∆°n v√† k·∫øt th√∫c

FORMAT PH·∫¢N H·ªíI:
- Feedback ng·∫Øn (1-2 c√¢u)
- C√¢u h·ªèi ti·∫øp theo (n·∫øu c√≥)
- T·ªïng kh√¥ng qu√° 3-4 c√¢u m·ªói l∆∞·ª£t

V√≠ d·ª•:
"T·ªët l·∫Øm! Em ƒë√£ n√™u ƒë∆∞·ª£c quy tr√¨nh 3 b∆∞·ªõc r·∫•t r√µ r√†ng. B√¢y gi·ªù h√£y chuy·ªÉn sang c√¢u h·ªèi ti·∫øp theo: [C√¢u h·ªèi t·ª´ database]"

Quy t·∫Øc:
- M·ªói l·∫ßn ch·ªâ ƒë·∫∑t 1 c√¢u h·ªèi
- C√¢u h·ªèi ng·∫Øn g·ªçn, r√µ r√†ng (kh√¥ng qu√° 2-3 c√¢u)
- Ph·∫£n h·ªìi ng·∫Øn g·ªçn (2-4 c√¢u) tr∆∞·ªõc khi ƒë·∫∑t c√¢u ti·∫øp theo
- Kh√¥ng l·∫∑p l·∫°i c√¢u h·ªèi ƒë√£ h·ªèi
- Th√≠ch nghi v·ªõi tr√¨nh ƒë·ªô ·ª©ng vi√™n
"""

        return system_prompt

    def generate_evaluation(self, conversation_history):
        """Generate final evaluation based on interview conversation"""
        try:
            evaluation_prompt = """
D·ª±a tr√™n cu·ªôc ph·ªèng v·∫•n v·ª´a r·ªìi, h√£y ƒë∆∞a ra ƒë√°nh gi√° t·ªïng k·∫øt chi ti·∫øt:

## 1. ƒêI·ªÇM M·∫†NH (Strengths):
- Li·ªát k√™ 3-5 ƒëi·ªÉm m·∫°nh n·ªïi b·∫≠t c·ªßa ·ª©ng vi√™n

## 2. ƒêI·ªÇM C·∫¶N C·∫¢I THI·ªÜN (Areas for Improvement):
- Li·ªát k√™ 2-4 ƒëi·ªÉm c·∫ßn c·∫£i thi·ªán

## 3. ƒê√ÅNH GI√Å T·ªîNG QUAN:
- Nh·∫≠n x√©t chung v·ªÅ performance
- G·ª£i √Ω cho l·∫ßn ph·ªèng v·∫•n ti·∫øp theo

H√£y vi·∫øt ƒë√°nh gi√° b·∫±ng markdown format, ng·∫Øn g·ªçn nh∆∞ng c·ª• th·ªÉ.
"""

            messages = conversation_history + [{
                'role': 'user',
                'content': evaluation_prompt
            }]

            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=800
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"[ERROR] Generate evaluation failed: {str(e)}")
            return f"Xin l·ªói, kh√¥ng th·ªÉ t·∫°o ƒë√°nh gi√°: {str(e)}"

    def generate_overall_assessment(self, evaluations_list):
        """Generate overall assessment from multiple interview evaluations"""
        try:
            # Build prompt for overall assessment
            evaluations_text = "\n\n---\n\n".join([
                f"**Phi√™n ph·ªèng v·∫•n {i+1}:**\n{eval_text}" 
                for i, eval_text in enumerate(evaluations_list) if eval_text
            ])

            assessment_prompt = f"""
D·ª±a tr√™n c√°c ƒë√°nh gi√° ph·ªèng v·∫•n sau ƒë√¢y c·ªßa c√πng m·ªôt c√° nh√¢n, h√£y t·ªïng h·ª£p ƒë√°nh gi√° t·ªïng quan:

{evaluations_text}

H√£y t·∫°o ƒë√°nh gi√° t·ªïng h·ª£p theo ƒë·ªãnh d·∫°ng markdown v·ªõi c√°c ph·∫ßn sau:

## üìä ƒêI·ªÇM M·∫†NH (Strengths)
Li·ªát k√™ 2-4 ƒëi·ªÉm m·∫°nh chung v√† nh·∫•t qu√°n nh·∫•t c·ªßa c√° nh√¢n n√†y qua c√°c l·∫ßn ph·ªèng v·∫•n. M·ªói ƒëi·ªÉm b·∫Øt ƒë·∫ßu b·∫±ng "- ".

## üìâ ƒêI·ªÇM Y·∫æU (Weaknesses)
Li·ªát k√™ 2-4 ƒëi·ªÉm y·∫øu ho·∫∑c ƒëi·ªÉm c·∫ßn c·∫£i thi·ªán c·ªßa c√° nh√¢n n√†y. M·ªói ƒëi·ªÉm b·∫Øt ƒë·∫ßu b·∫±ng "- ".

## üöÄ L·ªò TR√åNH PH√ÅT TRI·ªÇN (Development Path)
ƒê·ªÅ xu·∫•t 2-4 ƒëi·ªÉm v·ªÅ l·ªô tr√¨nh ph√°t tri·ªÉn ph√π h·ª£p d·ª±a tr√™n ƒëi·ªÉm m·∫°nh v√† ƒëi·ªÉm y·∫øu ƒë√£ ph√¢n t√≠ch. M·ªói ƒëi·ªÉm b·∫Øt ƒë·∫ßu b·∫±ng "- ".

**L∆∞u √Ω:** 
- T·∫≠p trung v√†o c√°c xu h∆∞·ªõng v√† pattern chung, kh√¥ng ph·ª• thu·ªôc v√†o ng√†nh ngh·ªÅ hay v·ªã tr√≠ c·ª• th·ªÉ
- Vi·∫øt ng·∫Øn g·ªçn, c·ª• th·ªÉ, d·ªÖ hi·ªÉu
- ƒê·∫£m b·∫£o ƒë√∫ng format markdown
- C√°c ch·ªØ in ƒë·∫≠m v√† bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c ph·∫£i ƒë∆∞·ª£c gi·ªØ nguy√™n
"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': assessment_prompt
                }],
                temperature=0,  # Temperature = 0 for consistent results
                max_tokens=1000
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"[ERROR] Generate overall assessment failed: {str(e)}")
            return f"Xin l·ªói, kh√¥ng th·ªÉ t·∫°o ƒë√°nh gi√° t·ªïng h·ª£p: {str(e)}"

    def extract_text_from_vision(self, base64_contents: list, filename: str) -> str:
        """
        Extract text from image/PDF using Azure GPT-4 Vision API.
        Similar to AIChatAssistant's image analysis approach.

        Args:
            base64_contents: List of dicts with base64 image data. For PDFs with multiple pages,
                           this will be a list of images (one per page).
                           Format: [{'type': 'image_url', 'image_url': {'url': 'data:image/...;base64,...'}}, ...]
            filename: Original filename for context

        Returns:
            Extracted text from all images/pages
        """
        try:
            print(f"[INFO] Extracting text from {filename} using Azure Vision API ({len(base64_contents)} page(s))...")

            # Build content array with text prompt + all images
            content = [
                {
                    "type": "text",
                    "text": f"Please extract ALL text from this document ({filename}). It has {len(base64_contents)} page(s). Maintain the structure and format. Extract everything you see from all pages."
                }
            ]

            # Add all images to the content array
            content.extend(base64_contents)

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a helpful assistant that extracts ALL text content from images and PDF documents. Extract the text exactly as it appears, maintaining structure and formatting. If it's a CV/resume or job description, extract all information including contact details, skills, experience, education, requirements, etc."
                    },
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                temperature=0,
                max_tokens=4000  # Increased for multi-page PDFs
            )

            extracted_text = response.choices[0].message.content.strip()
            print(f"[SUCCESS] Extracted {len(extracted_text)} characters from {filename}")
            return extracted_text

        except Exception as e:
            print(f"[ERROR] Vision API extraction failed for {filename}: {str(e)}")
            raise Exception(f"Kh√¥ng th·ªÉ ƒë·ªçc n·ªôi dung t·ª´ {filename}: {str(e)}")

    def analyze_files_and_extract_info(self, file_texts: list, language: str = 'vi') -> dict:
        """
        Analyze uploaded files and extract structured information using AI.

        Args:
            file_texts: List of extracted text strings from uploaded files
            language: Interview language ('vi' or 'en')

        Returns:
            Dictionary with extracted information:
            {
                'position': str,
                'industry': str,
                'candidate_skills': list[str],
                'experience_level': str,
                'job_requirements': str,
                'candidate_background': str,
                'key_focus_areas': list[str]
            }
        """
        try:
            # Combine all file texts
            combined_text = "\n\n---\n\n".join([
                f"**Document {i+1}:**\n{text}"
                for i, text in enumerate(file_texts) if text
            ])

            # Build analysis prompt
            analysis_prompt = f"""
Analyze the following documents and extract structured information about the candidate and job position:

{combined_text}

Please analyze the above documents and extract the following information. Return ONLY valid JSON with no additional explanation:

{{
  "position": "detected job title (e.g., Senior Software Engineer, Marketing Manager, HR Specialist)",
  "industry": "one of: IT, Marketing, Sales, Finance, HR, or closest match",
  "candidate_skills": ["skill1", "skill2", "skill3", ...],
  "experience_level": "Intern, Junior, Senior, or Manager based on years of experience",
  "job_requirements": "summary of key job requirements if JD is provided, otherwise N/A",
  "candidate_background": "brief summary of candidate's experience and qualifications",
  "key_focus_areas": ["area1", "area2", "area3", ...]
}}

Guidelines:
- If position is unclear, infer from skills and experience
- Industry must be one of: IT, Marketing, Sales, Finance, HR
- candidate_skills: extract 5-10 most relevant skills
- experience_level: estimate based on years of experience or role level
- key_focus_areas: 3-5 areas to focus on during interview
- If information is missing, use reasonable defaults

Respond ONLY with valid JSON, no markdown formatting, no explanation.
"""

            # Call GPT with temperature=0 for consistency
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': analysis_prompt
                }],
                temperature=0,
                max_tokens=1000
            )

            result_text = response.choices[0].message.content.strip()

            # Remove markdown code blocks if present
            if result_text.startswith('```'):
                result_text = result_text.split('```')[1]
                if result_text.startswith('json'):
                    result_text = result_text[4:]
                result_text = result_text.strip()

            # Parse JSON
            import json
            extracted_info = json.loads(result_text)

            print(f"[SUCCESS] Extracted info: position={extracted_info.get('position')}, industry={extracted_info.get('industry')}")

            return extracted_info

        except json.JSONDecodeError as e:
            print(f"[ERROR] Failed to parse AI response as JSON: {str(e)}")
            print(f"[DEBUG] AI response: {result_text}")
            raise Exception(f"AI kh√¥ng th·ªÉ ph√¢n t√≠ch t√†i li·ªáu. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c s·ª≠ d·ª•ng mode chu·∫©n.")
        except Exception as e:
            print(f"[ERROR] File analysis failed: {str(e)}")
            raise Exception(f"L·ªói khi ph√¢n t√≠ch t√†i li·ªáu: {str(e)}")

    def generate_personalized_questions(self, extracted_info: dict, style: str, language: str) -> list:
        """
        Generate personalized interview questions based on extracted candidate/job info.

        Args:
            extracted_info: Dictionary with candidate and job information
            style: Interview style
            language: Interview language ('vi' or 'en')

        Returns:
            List of question dictionaries with structure:
            [
                {
                    'section': str,
                    'question_text': str,
                    'question_type': str,
                    'purpose': str,
                    'expected_duration_minutes': int,
                    'guidelines': {'must_have': [...], 'should_avoid': [...]},
                    'popup_questions': [...]
                },
                ...
            ]
        """
        try:
            import json

            lang_instruction = 'in Vietnamese (ti·∫øng Vi·ªát)' if language == 'vi' else 'in English'

            # Build question generation prompt
            question_prompt = f"""
You are an expert interview question designer. Based on the candidate and job information below, create 10-15 structured interview questions {lang_instruction}.

Candidate & Job Info:
{json.dumps(extracted_info, indent=2, ensure_ascii=False)}

Interview Style: {style}

Create questions following this structure:
- 3-4 questions for Section 1: Background & Experience (Kinh nghi·ªám & N·ªÅn t·∫£ng)
- 3-4 questions for Section 2: Technical/Domain Skills (K·ªπ nƒÉng chuy√™n m√¥n)
- 2-3 questions for Section 3: Behavioral & Soft Skills (K·ªπ nƒÉng m·ªÅm)
- 2-3 questions for Section 4: Future Goals & Cultural Fit (ƒê·ªãnh h∆∞·ªõng & Ph√π h·ª£p vƒÉn h√≥a)

Each question must have:
- section: The section name
- question_text: The main question (tailored to candidate's background)
- question_type: "Behavioral", "Technical", or "Situational"
- purpose: What this question assesses (1 sentence)
- expected_duration_minutes: 2-5 minutes
- guidelines: {{"must_have": ["point1", "point2"], "should_avoid": ["point1", "point2"]}}
- popup_questions: 2-3 follow-up questions for deeper exploration

Important:
- Questions MUST be {lang_instruction}
- Tailor questions to the candidate's specific skills, experience level, and the job requirements
- For {extracted_info.get('experience_level', 'Junior')} level, adjust difficulty appropriately
- Include specific skills from candidate_skills where relevant
- Make questions practical and job-relevant

Return ONLY a valid JSON array of question objects, no markdown formatting, no explanation.

Example structure:
[
  {{
    "section": "Section 1: Background & Experience",
    "question_text": "...",
    "question_type": "Behavioral",
    "purpose": "...",
    "expected_duration_minutes": 3,
    "guidelines": {{
      "must_have": ["specific example", "quantifiable results"],
      "should_avoid": ["vague answers", "no concrete details"]
    }},
    "popup_questions": ["Follow-up 1?", "Follow-up 2?"]
  }}
]
"""

            # Call GPT with temperature=0.7 for creativity
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': question_prompt
                }],
                temperature=0.7,
                max_tokens=3000
            )

            result_text = response.choices[0].message.content.strip()

            # Remove markdown code blocks if present
            if result_text.startswith('```'):
                result_text = result_text.split('```')[1]
                if result_text.startswith('json'):
                    result_text = result_text[4:]
                result_text = result_text.strip()

            # Parse JSON
            questions = json.loads(result_text)

            # Validate structure
            if not isinstance(questions, list) or len(questions) < 5:
                raise Exception("AI generated insufficient questions")

            print(f"[SUCCESS] Generated {len(questions)} personalized questions")

            return questions

        except json.JSONDecodeError as e:
            print(f"[ERROR] Failed to parse AI response as JSON: {str(e)}")
            print(f"[DEBUG] AI response: {result_text}")
            raise Exception("AI kh√¥ng th·ªÉ t·∫°o c√¢u h·ªèi. Vui l√≤ng th·ª≠ l·∫°i.")
        except Exception as e:
            print(f"[ERROR] Question generation failed: {str(e)}")
            raise Exception(f"L·ªói khi t·∫°o c√¢u h·ªèi: {str(e)}")


# Singleton instance
gpt_service = AzureGPTService()

def generate_final_evaluation(session_id, conversation_history):
    """Generate final evaluation for interview session"""
    return gpt_service.generate_evaluation(conversation_history)