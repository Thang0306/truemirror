import os
from openai import OpenAI

class AzureGPTService:
    def __init__(self):
        # Azure OpenAI Configuration - using standard OpenAI client with base_url
        api_key = os.getenv('AZURE_OPENAI_KEY')
        base_url = os.getenv('AZURE_OPENAI_BASE_URL')

        if not api_key or not base_url:
            raise ValueError("AZURE_OPENAI_KEY and AZURE_OPENAI_BASE_URL must be set")

        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        self.model = os.getenv('AZURE_OPENAI_DEPLOYMENT', 'gpt-5-mini')
        print(f"[INFO] Azure OpenAI initialized: model={self.model}, base_url={base_url}")

    def get_chat_response_stream(self, conversation_history):
        """
        Get streaming chat response from Azure OpenAI
        conversation_history: list of {role, content} dicts
        Yields: content chunks from AI response
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=conversation_history,
                # temperature removed as gpt-5-mini only supports default (1)
                max_completion_tokens=4000,
                stream=True
            )

            for chunk in response:
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        # Debug: print chunk content
                        print(f"[DEBUG] Chunk: {repr(delta.content)}")
                        yield delta.content

        except Exception as e:
            print(f"[ERROR] Azure OpenAI stream failed: {str(e)}")
            yield f"Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra: {str(e)}"

    def build_interview_system_prompt(self, position, industry, style, language, uploaded_files_info=None):
        """Build system prompt based on interview configuration"""

        style_instructions = {
            'NghiÃªm tÃºc': 'Báº¡n lÃ  má»™t interviewer nghiÃªm tÃºc vÃ  chuyÃªn nghiá»‡p. Báº¡n Ä‘áº·t cÃ¢u há»i sÃ¢u sáº¯c vÃ  Ä‘Ã¡nh giÃ¡ ká»¹ nÄƒng má»™t cÃ¡ch chÃ­nh xÃ¡c.',
            'ThÃ¢n thiá»‡n': 'Báº¡n lÃ  má»™t interviewer thÃ¢n thiá»‡n vÃ  khuyáº¿n khÃ­ch. Báº¡n táº¡o khÃ´ng khÃ­ thoáº£i mÃ¡i nhÆ°ng váº«n Ä‘Ã¡nh giÃ¡ Ä‘áº§y Ä‘á»§ ká»¹ nÄƒng.',
            'KhÃ³ tÃ­nh': 'Báº¡n lÃ  má»™t interviewer khÃ³ tÃ­nh vÃ  yÃªu cáº§u cao. Báº¡n Ä‘áº·t cÃ¢u há»i thÃ¡ch thá»©c vÃ  pháº£n biá»‡n cÃ¡c cÃ¢u tráº£ lá»i.'
        }

        lang_instruction = ''
        if language == 'vi':
            lang_instruction = 'Báº¡n PHáº¢I tráº£ lá»i HOÃ€N TOÃ€N báº±ng tiáº¿ng Viá»‡t.'
        else:
            lang_instruction = 'You MUST respond ENTIRELY in English.'

        # Add personalized candidate context if available
        candidate_context = ""
        if uploaded_files_info:
            import json
            info = json.loads(uploaded_files_info) if isinstance(uploaded_files_info, str) else uploaded_files_info
            candidate_context = f"""
CANDIDATE CONTEXT (from uploaded documents):
- Skills: {', '.join(info.get('candidate_skills', []))}
- Experience Level: {info.get('experience_level', 'Unknown')}
- Background: {info.get('candidate_background', 'N/A')}
- Key Focus Areas: {', '.join(info.get('key_focus_areas', []))}

Use this context to tailor your questions and feedback to the candidate's specific background.
"""

        system_prompt = f"""
{style_instructions.get(style, style_instructions['NghiÃªm tÃºc'])}

Báº¡n tÃªn lÃ  TrueMirror, lÃ  má»™t AI Interviewer, giá»›i tÃ­nh ná»¯. Báº¡n
Ä‘ang phá»ng váº¥n á»©ng viÃªn cho vá»‹ trÃ­ {position} trong ngÃ nh {industry}.

{candidate_context}

{lang_instruction}

FLOW PHá»ŽNG Váº¤N LINH HOáº T:
Báº¡n Ä‘Æ°á»£c cung cáº¥p má»™t bá»™ cÃ¢u há»i cÃ³ cáº¥u trÃºc bÃªn dÆ°á»›i. HÃ£y tuÃ¢n thá»§ flow sau:

1. Báº®T Äáº¦U: ChÃ o há»i ngáº¯n gá»n, giá»›i thiá»‡u báº£n thÃ¢n lÃ  "TrueMirror" (KHÃ”NG dÃ¹ng [TÃªn] hay tÃªn giáº£ Ä‘á»‹nh khÃ¡c) vÃ  há»i cÃ¢u há»i Ä‘áº§u tiÃªn tá»« Section 1.

2. TRONG QUÃ TRÃŒNH:
   - Láº¯ng nghe cÃ¢u tráº£ lá»i cá»§a á»©ng viÃªn
   - ÄÆ°a ra feedback ngáº¯n gá»n vÃ  real-time (1-2 cÃ¢u) vá» cÃ¢u tráº£ lá»i:
     * Náº¿u tá»‘t: Khen ngá»£i Ä‘iá»ƒm máº¡nh cá»¥ thá»ƒ
     * Náº¿u thiáº¿u: Gá»£i Ã½ nháº¹ nhÃ ng Ä‘iá»ƒm cáº§n bá»• sung
   - ÄÃ¡nh giÃ¡ ná»™i bá»™ (khÃ´ng nÃ³i ra) dá»±a trÃªn guidelines (must_have/should_avoid)
   - Náº¿u cÃ¢u tráº£ lá»i chÆ°a Ä‘á»§ chi tiáº¿t: Há»i POP-UP question Ä‘á»ƒ Ä‘Ã o sÃ¢u
   - Náº¿u cÃ¢u tráº£ lá»i Ä‘Ã£ Ä‘á»§: Chuyá»ƒn sang cÃ¢u há»i tiáº¿p theo

3. TÃNH LINH HOáº T:
   - Náº¿u á»©ng viÃªn há»i láº¡i hoáº·c cáº§n lÃ m rÃµ: Tráº£ lá»i tá»± nhiÃªn, há»¯u Ã­ch
   - Náº¿u á»©ng viÃªn Ä‘i chá»‡ch topic: Nháº¹ nhÃ ng dáº«n vá» cÃ¢u há»i chÃ­nh
   - Náº¿u á»©ng viÃªn stress: Äiá»u chá»‰nh tone thÃ¢n thiá»‡n hÆ¡n
   - Cháº¥p nháº­n cÃ¢u tráº£ lá»i ngáº¯n náº¿u á»©ng viÃªn khÃ´ng cÃ³ kinh nghiá»‡m (Intern/Junior)

4. THá»¨ Tá»° CÃ‚U Há»ŽI:
   - Äi theo thá»© tá»± Section â†’ Question trong bá»™ cÃ¢u há»i
   - Äáº£m báº£o há»i Ä‘á»§ cÃ¢u há»i quan trá»ng nháº¥t tá»« má»—i section
   - CÃ³ thá»ƒ skip cÃ¢u há»i náº¿u á»©ng viÃªn Ä‘Ã£ tráº£ lá»i tá»± nhiÃªn trong cÃ¢u trÆ°á»›c

5. Káº¾T THÃšC:
   - Sau khi há»i xong cÃ¡c cÃ¢u há»i chÃ­nh: Há»i xem á»©ng viÃªn cÃ³ cÃ¢u há»i nÃ o khÃ´ng
   - Cáº£m Æ¡n vÃ  káº¿t thÃºc

FORMAT PHáº¢N Há»’I:
- Feedback ngáº¯n (1-2 cÃ¢u)
- CÃ¢u há»i tiáº¿p theo (náº¿u cÃ³)
- Tá»•ng khÃ´ng quÃ¡ 3-4 cÃ¢u má»—i lÆ°á»£t

VÃ­ dá»¥:
"Tá»‘t láº¯m! Em Ä‘Ã£ nÃªu Ä‘Æ°á»£c quy trÃ¬nh 3 bÆ°á»›c ráº¥t rÃµ rÃ ng. BÃ¢y giá» hÃ£y chuyá»ƒn sang cÃ¢u há»i tiáº¿p theo: [CÃ¢u há»i tá»« database]"

Quy táº¯c:
- Má»—i láº§n chá»‰ Ä‘áº·t 1 cÃ¢u há»i
- CÃ¢u há»i ngáº¯n gá»n, rÃµ rÃ ng (khÃ´ng quÃ¡ 2-3 cÃ¢u)
- Pháº£n há»“i ngáº¯n gá»n (2-4 cÃ¢u) trÆ°á»›c khi Ä‘áº·t cÃ¢u tiáº¿p theo
- KhÃ´ng láº·p láº¡i cÃ¢u há»i Ä‘Ã£ há»i
- ThÃ­ch nghi vá»›i trÃ¬nh Ä‘á»™ á»©ng viÃªn
"""

        return system_prompt

    def generate_evaluation(self, conversation_history):
        """Generate final evaluation based on interview conversation"""
        try:
            evaluation_prompt = """
Dá»±a trÃªn cuá»™c phá»ng váº¥n vá»«a rá»“i, hÃ£y Ä‘Æ°a ra Ä‘Ã¡nh giÃ¡ tá»•ng káº¿t chi tiáº¿t:

## 1. ÄIá»‚M Máº NH (Strengths):
- Liá»‡t kÃª 3-5 Ä‘iá»ƒm máº¡nh ná»•i báº­t cá»§a á»©ng viÃªn

## 2. ÄIá»‚M Cáº¦N Cáº¢I THIá»†N (Areas for Improvement):
- Liá»‡t kÃª 2-4 Ä‘iá»ƒm cáº§n cáº£i thiá»‡n

## 3. ÄÃNH GIÃ Tá»”NG QUAN:
- Nháº­n xÃ©t chung vá» performance
- Gá»£i Ã½ cho láº§n phá»ng váº¥n tiáº¿p theo

HÃ£y viáº¿t Ä‘Ã¡nh giÃ¡ báº±ng markdown format, ngáº¯n gá»n nhÆ°ng cá»¥ thá»ƒ.
"""

            messages = conversation_history + [{
                'role': 'user',
                'content': evaluation_prompt
            }]

            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                # temperature removed for gpt-5-mini default (1)
                max_completion_tokens=5500
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"[ERROR] Generate evaluation failed: {str(e)}")
            return f"Xin lá»—i, khÃ´ng thá»ƒ táº¡o Ä‘Ã¡nh giÃ¡: {str(e)}"

    def generate_overall_assessment(self, evaluations_list):
        """Generate overall assessment from multiple interview evaluations"""
        try:
            # Build prompt for overall assessment
            evaluations_text = "\n\n---\n\n".join([
                f"**PhiÃªn phá»ng váº¥n {i+1}:**\n{eval_text}" 
                for i, eval_text in enumerate(evaluations_list) if eval_text
            ])

            assessment_prompt = f"""
Dá»±a trÃªn cÃ¡c Ä‘Ã¡nh giÃ¡ phá»ng váº¥n sau Ä‘Ã¢y cá»§a cÃ¹ng má»™t cÃ¡ nhÃ¢n, hÃ£y tá»•ng há»£p Ä‘Ã¡nh giÃ¡ tá»•ng quan:

{evaluations_text}

HÃ£y táº¡o Ä‘Ã¡nh giÃ¡ tá»•ng há»£p theo Ä‘á»‹nh dáº¡ng markdown vá»›i cÃ¡c pháº§n sau:

## ðŸ“Š ÄIá»‚M Máº NH (Strengths)
Liá»‡t kÃª 2-4 Ä‘iá»ƒm máº¡nh chung vÃ  nháº¥t quÃ¡n nháº¥t cá»§a cÃ¡ nhÃ¢n nÃ y qua cÃ¡c láº§n phá»ng váº¥n. Má»—i Ä‘iá»ƒm báº¯t Ä‘áº§u báº±ng "- ".

## ðŸ“‰ ÄIá»‚M Yáº¾U (Weaknesses)
Liá»‡t kÃª 2-4 Ä‘iá»ƒm yáº¿u hoáº·c Ä‘iá»ƒm cáº§n cáº£i thiá»‡n cá»§a cÃ¡ nhÃ¢n nÃ y. Má»—i Ä‘iá»ƒm báº¯t Ä‘áº§u báº±ng "- ".

## ðŸš€ Lá»˜ TRÃŒNH PHÃT TRIá»‚N (Development Path)
Äá» xuáº¥t 2-4 Ä‘iá»ƒm vá» lá»™ trÃ¬nh phÃ¡t triá»ƒn phÃ¹ há»£p dá»±a trÃªn Ä‘iá»ƒm máº¡nh vÃ  Ä‘iá»ƒm yáº¿u Ä‘Ã£ phÃ¢n tÃ­ch. Má»—i Ä‘iá»ƒm báº¯t Ä‘áº§u báº±ng "- ".

**LÆ°u Ã½:** 
- Táº­p trung vÃ o cÃ¡c xu hÆ°á»›ng vÃ  pattern chung, khÃ´ng phá»¥ thuá»™c vÃ o ngÃ nh nghá» hay vá»‹ trÃ­ cá»¥ thá»ƒ
- Viáº¿t ngáº¯n gá»n, cá»¥ thá»ƒ, dá»… hiá»ƒu
- Äáº£m báº£o Ä‘Ãºng format markdown
- CÃ¡c chá»¯ in Ä‘áº­m vÃ  biá»ƒu tÆ°á»£ng cáº£m xÃºc pháº£i Ä‘Æ°á»£c giá»¯ nguyÃªn
"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': assessment_prompt
                }],
                # temperature removed for gpt-5-mini default (1)
                max_completion_tokens=5000
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"[ERROR] Generate overall assessment failed: {str(e)}")
            return f"Xin lá»—i, khÃ´ng thá»ƒ táº¡o Ä‘Ã¡nh giÃ¡ tá»•ng há»£p: {str(e)}"

    def extract_text_from_vision(self, base64_contents: list, filename: str) -> str:
        """
        Extract text from image/PDF using Azure GPT-4 Vision API.
        Similar to AIChatAssistant's image analysis approach.

        Args:
            base64_contents: List of dicts with base64 image data. For PDFs with multiple pages,
                           this will be a list of images (one per page).
                           Format: [{'type': 'image_url', 'image_url': {'url': 'data:image/...;base64,...'}}, ...]
            filename: Original filename for context

        Returns:
            Extracted text from all images/pages
        """
        try:
            print(f"[INFO] Extracting text from {filename} using Azure Vision API ({len(base64_contents)} page(s))...")

            # Build content array with text prompt + all images
            content = [
                {
                    "type": "text",
                    "text": f"Please extract ALL text from this document ({filename}). It has {len(base64_contents)} page(s). Maintain the structure and format. Extract everything you see from all pages."
                }
            ]

            # Add all images to the content array
            content.extend(base64_contents)

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a helpful assistant that extracts ALL text content from images and PDF documents. Extract the text exactly as it appears, maintaining structure and formatting. If it's a CV/resume or job description, extract all information including contact details, skills, experience, education, requirements, etc."
                    },
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                # temperature removed for gpt-5-mini default (1)
                max_completion_tokens=4000  # Increased for multi-page PDFs
            )

            extracted_text = response.choices[0].message.content.strip()
            print(f"[SUCCESS] Extracted {len(extracted_text)} characters from {filename}")
            return extracted_text

        except Exception as e:
            print(f"[ERROR] Vision API extraction failed for {filename}: {str(e)}")
            raise Exception(f"KhÃ´ng thá»ƒ Ä‘á»c ná»™i dung tá»« {filename}: {str(e)}")

    def analyze_files_and_extract_info(self, file_texts: list, language: str = 'vi') -> dict:
        """
        Analyze uploaded files and extract structured information using AI.

        Args:
            file_texts: List of extracted text strings from uploaded files
            language: Interview language ('vi' or 'en')

        Returns:
            Dictionary with extracted information:
            {
                'position': str,
                'industry': str,
                'candidate_skills': list[str],
                'experience_level': str,
                'job_requirements': str,
                'candidate_background': str,
                'key_focus_areas': list[str]
            }
        """
        try:
            # Combine all file texts
            combined_text = "\n\n---\n\n".join([
                f"**Document {i+1}:**\n{text}"
                for i, text in enumerate(file_texts) if text
            ])

            # Build analysis prompt
            analysis_prompt = f"""
Analyze the following documents and extract structured information about the candidate and job position:

{combined_text}

Please analyze the above documents and extract the following information. Return ONLY valid JSON with no additional explanation:

{{
  "position": "detected job title (e.g., Senior Software Engineer, Marketing Manager, HR Specialist)",
  "industry": "one of: IT, Marketing, Sales, Finance, HR, or closest match",
  "candidate_skills": ["skill1", "skill2", "skill3", ...],
  "experience_level": "Intern, Junior, Senior, or Manager based on years of experience",
  "job_requirements": "summary of key job requirements if JD is provided, otherwise N/A",
  "candidate_background": "brief summary of candidate's experience and qualifications",
  "key_focus_areas": ["area1", "area2", "area3", ...]
}}

Guidelines:
- If position is unclear, infer from skills and experience
- Industry must be one of: IT, Marketing, Sales, Finance, HR
- candidate_skills: extract 5-10 most relevant skills
- experience_level: estimate based on years of experience or role level
- key_focus_areas: 3-5 areas to focus on during interview
- If information is missing, use reasonable defaults

Respond ONLY with valid JSON, no markdown formatting, no explanation.
"""

            # Call GPT with temperature=0 for consistency
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': analysis_prompt
                }],
                # temperature removed for gpt-5-mini default (1)
                max_completion_tokens=5000
            )

            result_text = response.choices[0].message.content.strip()

            # Robust JSON extraction using regex
            import re
            import json
            
            # Try to find JSON object within the text
            json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(0)
                try:
                    extracted_info = json.loads(json_str)
                except json.JSONDecodeError:
                    # If regex match fails to parse (e.g. invalid JSON syntax), try cleaning code blocks
                    pass
            
            # Fallback: legacy cleaning if regex didn't work or return valid JSON
            if 'extracted_info' not in locals():
                clean_text = result_text
                if '```' in clean_text:
                    parts = clean_text.split('```')
                    for part in parts:
                        if '{' in part and '}' in part:
                            clean_text = part
                            if clean_text.strip().startswith('json'):
                                clean_text = clean_text.strip()[4:]
                            break
                
                clean_text = clean_text.strip()
                extracted_info = json.loads(clean_text)

            print(f"[SUCCESS] Extracted info: position={extracted_info.get('position')}, industry={extracted_info.get('industry')}")

            return extracted_info

        except (json.JSONDecodeError, Exception) as e:
            print(f"[ERROR] Failed to parse AI response as JSON: {str(e)}")
            print(f"[DEBUG] AI response raw: {result_text}")
            # Try one last fallback: return a basic default structure if parsing fails completely
            # This prevents the "AI khÃ´ng thá»ƒ phÃ¢n tÃ­ch" error from blocking the user flow
            default_info = {
                "position": "Unknown Position",
                "industry": "General",
                "candidate_skills": [],
                "experience_level": "Junior",
                "job_requirements": "N/A",
                "candidate_background": "N/A",
                "key_focus_areas": ["General Fit", "Communication"]
            }
            print("[WARN] Using default fallback info due to parsing error.")
            return default_info
        except Exception as e:
            print(f"[ERROR] File analysis failed: {str(e)}")
            raise Exception(f"Lá»—i khi phÃ¢n tÃ­ch tÃ i liá»‡u: {str(e)}")

    def generate_personalized_questions(self, extracted_info: dict, style: str, language: str) -> list:
        """
        Generate personalized interview questions based on extracted candidate/job info.

        Args:
            extracted_info: Dictionary with candidate and job information
            style: Interview style
            language: Interview language ('vi' or 'en')

        Returns:
            List of question dictionaries with structure:
            [
                {
                    'section': str,
                    'question_text': str,
                    'question_type': str,
                    'purpose': str,
                    'expected_duration_minutes': int,
                    'guidelines': {'must_have': [...], 'should_avoid': [...]},
                    'popup_questions': [...]
                },
                ...
            ]
        """
        try:
            import json

            lang_instruction = 'in Vietnamese (tiáº¿ng Viá»‡t)' if language == 'vi' else 'in English'

            # Build question generation prompt
            question_prompt = f"""
You are an expert interview question designer. Based on the candidate and job information below, create 10-15 structured interview questions {lang_instruction}.

Candidate & Job Info:
{json.dumps(extracted_info, indent=2, ensure_ascii=False)}

Interview Style: {style}

Create questions following this structure:
- 3-4 questions for Section 1: Background & Experience
- 3-4 questions for Section 2: Technical/Domain Skills
- 2-3 questions for Section 3: Behavioral & Soft Skills
- 2-3 questions for Section 4: Future Goals & Cultural Fit

Each question must be a JSON object with:
- section: Section name
- question_text: The question content
- question_type: "Behavioral", "Technical", or "Situational"
- purpose: Assessment purpose
- expected_duration_minutes: Duration (int)
- guidelines: {{ "must_have": [], "should_avoid": [] }}
- popup_questions: [ "Follow-up 1", "Follow-up 2" ]

IMPORTANT:
- Return a SINGLE valid JSON object with a key "questions" containing the list.
- Example: {{ "questions": [ {{...}}, {{...}} ] }}
- Do NOT use markdown formatting (no ```json).
- Content must be {lang_instruction}.
"""

            # Call GPT
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': question_prompt
                }],
                # temperature removed for gpt-5-mini default (1)
                max_completion_tokens=5000
            )

            result_text = response.choices[0].message.content.strip()
            
            # Extract JSON using regex (looking for object with "questions" key or just list)
            import re
            questions = []
            
            # Try to find JSON object structure first
            json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
            if json_match:
                try:
                    data = json.loads(json_match.group(0))
                    if 'questions' in data and isinstance(data['questions'], list):
                        questions = data['questions']
                except:
                    pass
            
            # If that failed, try finding a list structure directly
            if not questions:
                list_match = re.search(r'\[.*\]', result_text, re.DOTALL)
                if list_match:
                    try:
                        questions = json.loads(list_match.group(0))
                    except:
                        pass

            # Fallback cleaning if regex failed
            if not questions:
                if result_text.startswith('```'):
                    result_text = result_text.split('```')[1]
                    if result_text.startswith('json'):
                        result_text = result_text[4:]
                    result_text = result_text.strip()
                try:
                    parsed = json.loads(result_text)
                    if isinstance(parsed, dict) and 'questions' in parsed:
                        questions = parsed['questions']
                    elif isinstance(parsed, list):
                        questions = parsed
                except:
                    pass

            # Validate
            if not isinstance(questions, list) or len(questions) < 3:
                raise Exception("Insufficient valid questions generated")

            print(f"[SUCCESS] Generated {len(questions)} personalized questions")
            return questions

        except Exception as e:
            print(f"[ERROR] Question generation failed: {str(e)}")
            print(f"[DEBUG] AI response raw: {result_text}")
            
            # ROBUST FALLBACK: Return default questions instead of crashing
            print("[WARN] Using fallback questions due to generation error.")
            
            fallback_qs = [
                {
                    "section": "Section 1: Background & Experience",
                    "question_text": "HÃ£y giá»›i thiá»‡u ngáº¯n gá»n vá» báº£n thÃ¢n vÃ  nhá»¯ng kinh nghiá»‡m lÃ m viá»‡c ná»•i báº­t nháº¥t cá»§a báº¡n liÃªn quan Ä‘áº¿n vá»‹ trÃ­ nÃ y." if language == 'vi' else "Please briefly introduce yourself and highlight your most relevant work experience for this position.",
                    "question_type": "Behavioral",
                    "purpose": "Ice breaker and background check",
                    "expected_duration_minutes": 3,
                    "guidelines": {"must_have": ["Overview of experience"], "should_avoid": ["Too detailed personal life"]},
                    "popup_questions": []
                },
                {
                    "section": "Section 2: Technical Skills",
                    "question_text": "Trong dá»± Ã¡n gáº§n Ä‘Ã¢y nháº¥t, báº¡n Ä‘Ã£ gáº·p pháº£i thá»­ thÃ¡ch ká»¹ thuáº­t (hoáº·c chuyÃªn mÃ´n) nÃ o khÃ³ khÄƒn nháº¥t vÃ  báº¡n Ä‘Ã£ giáº£i quyáº¿t nÃ³ nhÆ° tháº¿ nÃ o?" if language == 'vi' else "In your most recent project, what was the most challenging technical (or professional) problem you faced, and how did you resolve it?",
                    "question_type": "Technical",
                    "purpose": "Problem solving skills",
                    "expected_duration_minutes": 5,
                    "guidelines": {"must_have": ["STAR method", "Specific solution"], "should_avoid": ["Vague description"]},
                    "popup_questions": ["What would you do differently?"]
                },
                 {
                    "section": "Section 3: Soft Skills",
                    "question_text": "HÃ£y ká»ƒ vá» má»™t láº§n báº¡n pháº£i thuyáº¿t phá»¥c ngÆ°á»i khÃ¡c cháº¥p nháº­n Ã½ kiáº¿n cá»§a mÃ¬nh. Káº¿t quáº£ ra sao?" if language == 'vi' else "Tell me about a time you had to persuade someone to accept your idea. What was the outcome?",
                    "question_type": "Behavioral",
                    "purpose": "Communication and influence",
                    "expected_duration_minutes": 4,
                    "guidelines": {"must_have": ["Context", "Action"], "should_avoid": []},
                    "popup_questions": []
                },
                {
                    "section": "Section 4: Goals",
                    "question_text": "Báº¡n Ä‘á»‹nh hÆ°á»›ng phÃ¡t triá»ƒn báº£n thÃ¢n nhÆ° tháº¿ nÃ o trong 2-3 nÄƒm tá»›i?" if language == 'vi' else "How do you see yourself developing in the next 2-3 years?",
                    "question_type": "Situational",
                    "purpose": "Career alignment",
                    "expected_duration_minutes": 3,
                    "guidelines": {"must_have": ["Clear goals"], "should_avoid": []},
                    "popup_questions": []
                }
            ]
            return fallback_qs


# Singleton instance
gpt_service = AzureGPTService()

def generate_final_evaluation(session_id, conversation_history):
    """Generate final evaluation for interview session"""
    return gpt_service.generate_evaluation(conversation_history)